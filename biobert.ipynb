{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09df7e79-4112-4a17-b24f-2e9faa6094d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df57d056-b6dc-4512-8b40-aa0d77581d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_name = \"../filtered_combined.xlsx\"\n",
    "df = pd.read_excel(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de885007-b219-4a94-b004-c05c448afae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Detect if GPU is available and set the device accordingly\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95340ec0-8476-498b-b805-c480bced2ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BioBERT model initialization\n",
    "model_name = \"dmis-lab/biobert-base-cased-v1.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name).to(device)  # Move model to the device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8408d3bc-80a4-4850-8620-d035ace58293",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"similar_trials_results.xlsx\"\n",
    "model_file = \"biobert_embeddings.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae405a5e-d501-4d87-80d6-d33944e2d17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a dataset class for tokenization\n",
    "class ClinicalTrialsDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length=512):\n",
    "        self.data = data  # This should be a list of texts\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data[idx]  # Access list item directly\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        return {key: val.squeeze(0).to(device) for key, val in encoding.items()}  # Return tensors and move to device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f65941c-317f-43eb-be61-c58c5ef3f67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings using BioBERT\n",
    "def generate_embeddings(texts, tokenizer, model, batch_size=16):\n",
    "    dataset = ClinicalTrialsDataset(texts, tokenizer)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    embeddings = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Generating embeddings\"):\n",
    "            input_ids = batch[\"input_ids\"]\n",
    "            attention_mask = batch[\"attention_mask\"]\n",
    "\n",
    "            # Move tensors to the device\n",
    "            input_ids = input_ids.to(device)\n",
    "            attention_mask = attention_mask.to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0, :]\n",
    "            embeddings.append(cls_embeddings.cpu().numpy())  # Move embeddings back to CPU for numpy conversion\n",
    "\n",
    "    return torch.tensor(np.vstack(embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6f7f631-455c-43c5-9721-acd56f28b31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the text data\n",
    "df[\"Combined_Text\"] = df[\"Combined Column\"].fillna(\"\")\n",
    "texts = df[\"Combined_Text\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74aea002-314e-4c01-aed1-42d05badefc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating embeddings: 100%|███████████████████████████████████████████████████████| 7374/7374 [19:26<00:00,  6.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings saved to biobert_embeddings.pt\n"
     ]
    }
   ],
   "source": [
    "# Check if embeddings are already saved\n",
    "if os.path.exists(model_file):\n",
    "    embeddings = torch.load(model_file)\n",
    "    print(\"Loaded embeddings from saved model.\")\n",
    "else:\n",
    "    # Generate embeddings for all clinical trials\n",
    "    embeddings = generate_embeddings(texts, tokenizer, model)\n",
    "    torch.save(embeddings, model_file)\n",
    "    print(f\"Embeddings saved to {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5951ac38-149f-4d63-8150-4dd53d3ec7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve top N similar trials\n",
    "def get_similar_trials(query_embedding, embeddings, top_n=10):\n",
    "    # Ensure the tensors are moved to CPU before passing to cosine_similarity\n",
    "    query_embedding_cpu = query_embedding.cpu().numpy()  # Move to CPU and convert to numpy\n",
    "    embeddings_cpu = embeddings.cpu().numpy()  # Move to CPU and convert to numpy\n",
    "\n",
    "    similarities = cosine_similarity(query_embedding_cpu, embeddings_cpu)\n",
    "    similar_indices = similarities.argsort(axis=1)[:, -top_n-1:-1][:, ::-1]\n",
    "    return similar_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "257628d0-22af-494a-9c83-88525e1267fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trials to evaluate\n",
    "evaluation_trials = [\"NCT00385736\", \"NCT00386607\", \"NCT03518073\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4854660f-1e28-444a-929b-b40258d90b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of NCT IDs to indices\n",
    "nct_id_to_index = {nct_id: idx for idx, nct_id in enumerate(df[\"nct_id\"])}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56f8ff0f-c377-48ab-bba3-910ab4b0b859",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Output DataFrame for similar trials\n",
    "output_writer = pd.ExcelWriter(output_file, engine=\"xlsxwriter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a73d720-8253-4597-8d2c-4685949383a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m similar_indices \u001b[38;5;241m=\u001b[39m get_similar_trials(query_embedding, embeddings)\n\u001b[0;32m      8\u001b[0m similar_trials \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[similar_indices[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m----> 9\u001b[0m similar_trials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity_Score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msimilar_indices\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Save the results to an Excel sheet\u001b[39;00m\n\u001b[0;32m     15\u001b[0m similar_trials\u001b[38;5;241m.\u001b[39mto_excel(output_writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[25], line 10\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      6\u001b[0m similar_indices \u001b[38;5;241m=\u001b[39m get_similar_trials(query_embedding, embeddings)\n\u001b[0;32m      8\u001b[0m similar_trials \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[similar_indices[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m      9\u001b[0m similar_trials[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilarity_Score\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mcosine_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membeddings\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m similar_indices[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     12\u001b[0m ]\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Save the results to an Excel sheet\u001b[39;00m\n\u001b[0;32m     15\u001b[0m similar_trials\u001b[38;5;241m.\u001b[39mto_excel(output_writer, sheet_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:216\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    212\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    213\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    214\u001b[0m         )\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    222\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    224\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    226\u001b[0m     )\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:1741\u001b[0m, in \u001b[0;36mcosine_similarity\u001b[1;34m(X, Y, dense_output)\u001b[0m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute cosine similarity between samples in X and Y.\u001b[39;00m\n\u001b[0;32m   1696\u001b[0m \n\u001b[0;32m   1697\u001b[0m \u001b[38;5;124;03mCosine similarity, or the cosine kernel, computes similarity as the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1737\u001b[0m \u001b[38;5;124;03m       [0.57..., 0.81...]])\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;66;03m# to avoid recursive import\u001b[39;00m\n\u001b[1;32m-> 1741\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_pairwise_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1743\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m normalize(X, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m Y:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:181\u001b[0m, in \u001b[0;36mcheck_pairwise_arrays\u001b[1;34m(X, Y, precomputed, dtype, accept_sparse, force_all_finite, ensure_all_finite, ensure_2d, copy)\u001b[0m\n\u001b[0;32m    179\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X, Y)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m([issparse(X), issparse(Y)]) \u001b[38;5;129;01mor\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[1;32m--> 181\u001b[0m     X, Y, dtype_float \u001b[38;5;241m=\u001b[39m \u001b[43m_return_float_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    183\u001b[0m     dtype_float \u001b[38;5;241m=\u001b[39m _find_matching_floating_dtype(X, Y, xp\u001b[38;5;241m=\u001b[39mxp)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\sklearn\\metrics\\pairwise.py:57\u001b[0m, in \u001b[0;36m_return_float_dtype\u001b[1;34m(X, Y)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m1. If dtype of X and Y is float32, then dtype float32 is returned.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m2. Else dtype float is returned.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m---> 57\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m Y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     Y_dtype \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "# Generate similar trials for evaluation NCT IDs\n",
    "for trial_id in evaluation_trials:\n",
    "    if trial_id in nct_id_to_index:\n",
    "        query_idx = nct_id_to_index[trial_id]\n",
    "        query_embedding = embeddings[query_idx].unsqueeze(0).to(device)  # Move query embedding to device\n",
    "        similar_indices = get_similar_trials(query_embedding, embeddings)\n",
    "\n",
    "        similar_trials = df.iloc[similar_indices[0]]\n",
    "        similar_trials[\"Similarity_Score\"] = [\n",
    "            cosine_similarity(query_embedding, embeddings[idx].unsqueeze(0).to(device)).item()\n",
    "            for idx in similar_indices[0]\n",
    "        ]\n",
    "\n",
    "        # Save the results to an Excel sheet\n",
    "        similar_trials.to_excel(output_writer, sheet_name=f\"{trial_id}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d51755c-51fb-47cd-9062-38548e41cf30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\1754189210.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Similarity_Score\"] = [\n",
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\1754189210.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Similarity_Score\"] = [\n",
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\1754189210.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Similarity_Score\"] = [\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_similar_trials(query_embedding, embeddings, top_n=10):\n",
    "    # Ensure both tensors are on the CPU before calling cosine_similarity\n",
    "    query_embedding_cpu = query_embedding.cpu().detach().numpy()\n",
    "    embeddings_cpu = embeddings.cpu().detach().numpy()\n",
    "\n",
    "    # Compute cosine similarity between the query and all embeddings\n",
    "    similarities = cosine_similarity(query_embedding_cpu, embeddings_cpu)\n",
    "    \n",
    "    # Get the indices of the top_n most similar trials (excluding the query itself)\n",
    "    similar_indices = similarities.argsort(axis=1)[:, -top_n-1:-1][:, ::-1]\n",
    "    \n",
    "    return similar_indices\n",
    "\n",
    "# Generate similar trials for evaluation NCT IDs\n",
    "for trial_id in evaluation_trials:\n",
    "    if trial_id in nct_id_to_index:\n",
    "        query_idx = nct_id_to_index[trial_id]\n",
    "        query_embedding = embeddings[query_idx].unsqueeze(0).to(device)  # Move query embedding to device\n",
    "        \n",
    "        # Get similar trial indices\n",
    "        similar_indices = get_similar_trials(query_embedding, embeddings)\n",
    "\n",
    "        # Retrieve the similar trials from the DataFrame\n",
    "        similar_trials = df.iloc[similar_indices[0]]\n",
    "        \n",
    "        # Calculate and store similarity scores\n",
    "        similar_trials[\"Similarity_Score\"] = [\n",
    "            cosine_similarity(query_embedding.cpu().detach().numpy().reshape(1, -1), embeddings[idx].cpu().detach().numpy().reshape(1, -1)).item()\n",
    "            for idx in similar_indices[0]\n",
    "        ]\n",
    "\n",
    "\n",
    "        # Save the results to an Excel sheet\n",
    "        similar_trials.to_excel(output_writer, sheet_name=f\"{trial_id}\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "283aac08-94f0-40d9-aef3-07a6fa72fea3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'XlsxWriter' object has no attribute 'save'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Save the output results\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43moutput_writer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSimilar trials saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'XlsxWriter' object has no attribute 'save'"
     ]
    }
   ],
   "source": [
    "# Save the output results\n",
    "output_writer.save()\n",
    "print(f\"Similar trials saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c5d56e5-38c5-482d-91e7-9dfdcb55dce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar trials saved to similar_trials.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming similar_trials is your DataFrame\n",
    "output_file = \"similar_trials.xlsx\"\n",
    "\n",
    "# Using XlsxWriter engine\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as output_writer:\n",
    "    similar_trials.to_excel(output_writer, index=False, sheet_name='Similar Trials')\n",
    "\n",
    "# No need to call save() or close() explicitly when using 'with' context manager\n",
    "print(f\"Similar trials saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16c402ba-90f5-4e90-82f0-f22093ead740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\3332667952.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Similarity_Score\"] = [\n",
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\3332667952.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Query_NCT_ID\"] = trial_id\n",
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\3332667952.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Similarity_Score\"] = [\n",
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\3332667952.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Query_NCT_ID\"] = trial_id\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar trials with NCT IDs saved to similar_trials_with_nct_id.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\3332667952.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Similarity_Score\"] = [\n",
      "C:\\Users\\yash-amzn\\AppData\\Local\\Temp\\ipykernel_1436\\3332667952.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  similar_trials[\"Query_NCT_ID\"] = trial_id\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "\n",
    "def get_similar_trials(query_embedding, embeddings, top_n=10):\n",
    "    # Ensure both tensors are on the CPU before calling cosine_similarity\n",
    "    query_embedding_cpu = query_embedding.cpu().detach().numpy()\n",
    "    embeddings_cpu = embeddings.cpu().detach().numpy()\n",
    "\n",
    "    # Compute cosine similarity between the query and all embeddings\n",
    "    similarities = cosine_similarity(query_embedding_cpu, embeddings_cpu)\n",
    "    \n",
    "    # Get the indices of the top_n most similar trials (excluding the query itself)\n",
    "    similar_indices = similarities.argsort(axis=1)[:, -top_n-1:-1][:, ::-1]\n",
    "    \n",
    "    return similar_indices\n",
    "\n",
    "# Generate similar trials for evaluation NCT IDs\n",
    "output_data = []  # List to collect the results for each NCT ID\n",
    "\n",
    "for trial_id in evaluation_trials:\n",
    "    if trial_id in nct_id_to_index:\n",
    "        query_idx = nct_id_to_index[trial_id]\n",
    "        query_embedding = embeddings[query_idx].unsqueeze(0).to(device)  # Move query embedding to device\n",
    "        \n",
    "        # Get similar trial indices\n",
    "        similar_indices = get_similar_trials(query_embedding, embeddings)\n",
    "\n",
    "        # Retrieve the similar trials from the DataFrame\n",
    "        similar_trials = df.iloc[similar_indices[0]]\n",
    "        \n",
    "        # Calculate and store similarity scores\n",
    "        similar_trials[\"Similarity_Score\"] = [\n",
    "            cosine_similarity(query_embedding.cpu().detach().numpy().reshape(1, -1), embeddings[idx].cpu().detach().numpy().reshape(1, -1)).item()\n",
    "            for idx in similar_indices[0]\n",
    "        ]\n",
    "        \n",
    "        # Add the NCT ID (trial_id) as a new column to track which trial it corresponds to\n",
    "        similar_trials[\"Query_NCT_ID\"] = trial_id\n",
    "        \n",
    "        # Append the results to the output list\n",
    "        output_data.append(similar_trials)\n",
    "\n",
    "# Combine all results into a single DataFrame\n",
    "final_results = pd.concat(output_data, ignore_index=True)\n",
    "\n",
    "# Save the results to an Excel sheet\n",
    "output_file = \"similar_trials_with_nct_id.xlsx\"\n",
    "with pd.ExcelWriter(output_file, engine='xlsxwriter') as output_writer:\n",
    "    final_results.to_excel(output_writer, index=False, sheet_name='Similar Trials')\n",
    "\n",
    "print(f\"Similar trials with NCT IDs saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4941aab8-87f0-4401-b645-364ee4407412",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
